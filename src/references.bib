@article{cv2020,
title = {Going to the core of hard resource-constrained project scheduling instances},
journal = {Computers & Operations Research},
volume = {121},
pages = {104976},
year = {2020},
issn = {0305-0548},
doi = {https://doi.org/10.1016/j.cor.2020.104976},
url = {https://www.sciencedirect.com/science/article/pii/S0305054820300939},
author = {José Coelho and Mario Vanhoucke},
keywords = {Resource-constrained project scheduling, Project networks, Resource constraints,},
abstract = {The resource-constrained project scheduling problem (RCPSP) is one of the most studied problems in the project scheduling literature, and aims at constructing a project schedule with a minimum makespan that satisfies both the precedence relations of the network and the limited availability of the renewable resources. The problem has attracted attention due to its NP hardness status, and different algorithms have been proposed that solve a wide variety of RCPSP instances to optimality or near-optimality. In this paper, we analyse the hardness of this problem from an experimental point-of-view by testing different algorithms on a huge set of existing instances and detect which ones are difficult to solve. To that purpose, we propose a three-phased approach that makes use of five elementary blocks, well-performing algorithms and a huge amount of computational power to transform easy RCPSP instances into very hard ones. The purpose of this study is to create insight and understanding into what makes an RCPSP instance hard, and propose a new dataset that consists of a small set of instances that are impossible to solve with the algorithms currently existing in the literature. These instances should be as small as possible in terms of number of activities and resources, and should be as diverse as possible in terms of network structure and resource strictness. Such a dataset should enable researchers to focus their attention on the development of radically new algorithms to solve the RCPSP rather than gradually improving current algorithms that can solve the existing RCPSP instances only slightly better.}
}

@article{masud2018variable,
  title={Variable selection for mixture and promotion time cure rate models},
  author={Masud, Abdullah and Tu, Wanzhu and Yu, Zhangsheng},
  journal={Statistical methods in medical research},
  volume={27},
  number={7},
  pages={2185--2199},
  year={2018},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{coelho2023new,
  title={New resource-constrained project scheduling instances for testing (meta-) heuristic scheduling algorithms},
  author={Coelho, Jos{\'e} and Vanhoucke, Mario},
  journal={Computers \& Operations Research},
  volume={153},
  pages={106165},
  year={2023},
  publisher={Elsevier}
}

@article{grambsch1994,
    author = {Grambsch, Patricia M. and Therneau, Terry M.},
    title = {Proportional hazards tests and diagnostics based on weighted residuals},
    journal = {Biometrika},
    volume = {81},
    number = {3},
    pages = {515-526},
    year = {1994},
    month = {09},
    issn = {0006-3444},
    doi = {10.1093/biomet/81.3.515},
    url = {https://doi.org/10.1093/biomet/81.3.515},
    eprint = {https://academic.oup.com/biomet/article-pdf/81/3/515/714158/81-3-515.pdf},
}


@article{asano2017assessing,
  title={Assessing the prediction accuracy of a cure model for censored survival data with long-term survivors: application to breast cancer data},
  author={Asano, Junichi and Hirakawa, Akihiro},
  journal={Journal of Biopharmaceutical statistics},
  volume={27},
  number={6},
  pages={918--932},
  year={2017},
  publisher={Taylor \& Francis}
}

@article{watermeyer2022partition,
  title={A partition-based branch-and-bound algorithm for the project duration problem with partially renewable resources and general temporal constraints},
  author={Watermeyer, Kai and Zimmermann, J{\"u}rgen},
  journal={OR spectrum},
  volume={44},
  number={2},
  pages={575--602},
  year={2022},
  publisher={Springer}
}
@inproceedings{creemers2021,
  title={The resource-constrained project scheduling problem: New benchmark results, 17th International Workshop on Project Management and Scheduling},
  author={Creemers, Stefan},
  year={2021},
  series       = {PMS},
  month        = {April},
  address      = {Toulouse, France},
}

@article{DEREYCK1996347,
title = {On the use of the complexity index as a measure of complexity in activity networks},
journal = {European Journal of Operational Research},
volume = {91},
number = {2},
pages = {347-366},
year = {1996},
issn = {0377-2217},
doi = {https://doi.org/10.1016/0377-2217(94)00344-0},
url = {https://www.sciencedirect.com/science/article/pii/0377221794003440},
author = {Bert {De Reyck} and Willy Herroelen},
keywords = {Project planning, Network complexity measure, Complexity index, Network reduction},
abstract = {A large number of optimal and suboptimal procedures have been developed for solving combinatorial problems modeled as activity networks. The need to differentiate between easy and hard problem instances and the interest in isolating the fundamental factors that determine the computing effort required by these procedures, inspired a number of researchers to develop various complexity measures. In this paper we investigate the relation between the hardness of a problem instance and the topological structure of its underlying network, as measured by the complexity index. We demonstrate through a series of experiments that the complexity index, defined as the minimum number of node reductions necessary to transform a general activity network to a series-parallel network, plays an important role in predicting the computing effort needed to solve easy and hard instances of the multiple resource-constrained project scheduling problem and the discrete time/cost trade-off problem.}
}
@article{ELMAGHRABY1980223,
title = {On the measurement of complexity in activity networks},
journal = {European Journal of Operational Research},
volume = {5},
number = {4},
pages = {223-234},
year = {1980},
issn = {0377-2217},
doi = {https://doi.org/10.1016/0377-2217(80)90053-3},
url = {https://www.sciencedirect.com/science/article/pii/0377221780900533},
author = {Salah E. Elmaghraby and Willy S. Herroelen},
abstract = {The measurement of the ‘complexity’ of activity networks seems to be needed in order to estimate the computing requirements and/or to validly compare alternative heuristic procedures. This paper critically evaluates past contributions to the problem, and explores the underlying concepts of measurement. It suggests that the objective of analysis of the network is a determining factor in the process of measurement, and discusses three different objectives; they are: to determine the critical path assuming deterministic time estimates; to determine the probability distribution function of project completion assuming random durations of the activities; and to determine the optimal schedule under limited availability of a single resource. It proposes the form of the measure of network complexity for each objective, and explicitly exhibits the form of the measure relative to the first objective based on a sample of 104 networks.}
}

@article{HERROELEN1998279,
title = {Resource-constrained project scheduling: A survey of recent developments},
journal = {Computers & Operations Research},
volume = {25},
number = {4},
pages = {279-302},
year = {1998},
issn = {0305-0548},
doi = {https://doi.org/10.1016/S0305-0548(97)00055-5},
url = {https://www.sciencedirect.com/science/article/pii/S0305054897000555},
author = {Willy Herroelen and Bert {De Reyck} and Erik Demeulemeester},
abstract = {We review recent advances in dealing with the resource-constrained project scheduling problem using an efficient depth-first branch-and-bound procedure, elaborating on the branching scheme, bounding calculations and dominance rules, and discuss the potential of using truncated branch-and-bound. We derive conclusions from the research on optimal solution procedures for the basic problem and subsequently illustrate extensions to a rich and realistic variety of related problems involving activity preemption, the use of ready times and deadlines, variable resource requirements and availabilities, generalized precedence relations, time/cost, time/resource and resource/resource trade-offs and non-regular objective functions.}
}

@article{kolisch1997psplib,
  title={PSPLIB-a project scheduling problem library: OR software-ORSEP operations research software exchange program},
  author={Kolisch, Rainer and Sprecher, Arno},
  journal={European journal of operational research},
  volume={96},
  number={1},
  pages={205--216},
  year={1997},
  publisher={Elsevier}
}

@phdthesis{amicoCureModelsSurvival2018,
  title = {Cure {{Models}} in {{Survival Analysis}}: {{From Modelling}} to {{Prediction Assessment}} of the {{Cure Fraction}}},
  author = {Amico, Ma{\"i}lis},
  year = {2018},
  month = nov,
  langid = {english},
  school = {Universit\'e catholique de Louvain and Katholieke Universiteit Leuven},
  file = {C:\Users\raisa_carmen\Zotero\storage\UIRB3W5A\view.pdf}
}

@article{suAnalysisSurvivalData2022,
  title = {Analysis of Survival Data with Cure Fraction and Variable Selection: {{A}} Pseudo-Observations Approach},
  shorttitle = {Analysis of Survival Data with Cure Fraction and Variable Selection},
  author = {Su, Chien-Lin and Chiou, Sy Han and Lin, Feng-Chang and Platt, Robert W},
  year = {2022},
  month = nov,
  journal = {Statistical Methods in Medical Research},
  volume = {31},
  number = {11},
  pages = {2037--2053},
  issn = {0962-2802},
  doi = {10.1177/09622802221108579},
  urldate = {2023-12-14},
  abstract = {In biomedical studies, survival data with a cure fraction (the proportion of subjects cured of disease) are commonly encountered. The mixture cure and bounded cumulative hazard models are two main types of cure fraction models when analyzing survival data with long-term survivors. In this article, in the framework of the Cox proportional hazards mixture cure model and bounded cumulative hazard model, we propose several estimators utilizing pseudo-observations to assess the effects of covariates on the cure rate and the risk of having the event of interest for survival data with a cure fraction. A variable selection procedure is also presented based on the pseudo-observations using penalized generalized estimating equations for proportional hazards mixture cure and bounded cumulative hazard models. Extensive simulation studies are conducted to examine the proposed methods. The proposed technique is demonstrated through applications to a melanoma study and a dental data set with high-dimensional covariates.},
  pmcid = {PMC9660265},
  pmid = {35754373},
  keywords = {regularization cure},
  file = {C\:\\Users\\raisa_carmen\\Zotero\\storage\\ANM87PJS\\Analysis of survival data with cure fraction and v.pdf;C\:\\Users\\raisa_carmen\\Zotero\\storage\\TT34XJDC\\Su e.a. - 2022 - Analysis of survival data with cure fraction and v.pdf}
}

@online{intsurv,
  author = {Wang, Wenjie and Chen, Kun, and Yan, Jun},
  title = {Package `intsurv': Integrative Survival Modeling},
  year = {2021},
  url = {https://cran.r-project.org/web/packages/intsurv/intsurv.pdf},
  urldate = {2023-11-25}
  }
