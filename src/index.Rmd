---
title: "Determining what makes an RCPSP hard to solve: A survival model analysis"
output:
  bookdown::html_document2:
    toc: true
    fig_caption: true
  bookdown::pdf_book:
    toc: true
    fig_caption: true
bibliography: references.bib
site: bookdown::bookdown_site
delete_merged_file: true
---

```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
library(kableExtra)
library(corrplot)
library(readxl)
library(rprojroot)
library(tidyverse)
library(zoo)
library(survival)
library(ggsurvfit)
library(knitr)
library(patchwork)
library(santoku)#chop_equal in stead of cut_number
source(find_root_file("src", "functions.R",
                      criterion = has_file("RCPSP_survival.Rproj")))
```
# Introduction

## Resource Constrained Project Scheduling Problem (RCPSP)

The Resource Constrained Project Scheduling Problem (RCPSP) is a well-known and extensively studied operations research (OR) problem.
In general, an RCPSP is a project (eg. building a house), characterized by several activities (eg. digging, building the floor, building the walls, adding electricity, installing windows,...) which all require a certain number of limited resources to be executed (eg. there are only 5 manual labourers available at the same time).
There are precedence constraints between the activities meaning that some activities cannot start before others are finished (eg; there has to be wall before we can add the windows).
The goal is to schedule the activities to minimize the total time to complete the project while respecting all precedence constraints and resource constraints.
It is an NP-hard problem which means that it cannot be solved to optimality in polynomial time.
Therefore, many algorithms (mostly branch-and-bound algorithms) have been developed over the years to be able to solve harder problems in shorter time.

Figure \@ref(fig:toy-rcpsp) shows a toy example of an RCPSP.
The top left shows the precedence constraints between activities.
It can be seen that activity three cannot start before activity 2 finishes.
The top right table shows the duration and resource use for each of the activities.
It can be seen that activity three needs two resources and that there are only two resources available in total.
This essentially means that no other activity can be performed in parallel with activity three.
The bottom figure shows the optimal solution where each activity is scheduled, respecting all precedence and resource constraints.
```{r toy-rcpsp, fig.cap = "A toy RCPSP example", out.width = "400px", echo = FALSE, include = TRUE}
knitr::include_graphics(
  path = find_root_file("rcpsp_example.png",
                        criterion = has_file("report.Rproj")),
  )
```


The aim of this paper is to develop a methodology to investigate what makes an RCPSP hard to solve for the currently existing algorithms.
The next two sections explain (1) the dataset that we will work with and (2) how one can describe the complexity of an RCPSP instance.

## Data source and description

Over the years, several RCPSP instance sets have been developed for researchers to test new algorithms.
In many papers on RCPSP algorithms, researchers illustrate the quality of a new algorithm by reporting how many instances of the set they can solve and how long it takes to solve them.

Recently, a [new website](http://solutionsupdate.ugent.be/rcpsp) was developed to make run times for different algorithms on different instance sets openly available.
Any researcher can upload their results and these results are openly available to download and compare.

In this article, we first explore the available datasets for the following instance sets which can be downloaded from [here](https://www.projectmanagement.ugent.be/research/data):

* PSPLIB dataset: although these datasets have been available for a long time, some instances still have not been solved [@kolisch1997psplib]. They are very well known and commonly referred to as "J##" where ## denote the number of activities in the network. Popular problem instance sets are J30, J60, J90 and J120.
* The Coelho-Vanhoucke (CV) dataset consists of 623 RCPSP instances. These instances are meant to be hard to solve for exact algorithms according to  @cv2020.

## RCPSP instance complexity

To describe instance complexity, many different parameters and indices are developed to approximate how hard an instance is to solve [@ELMAGHRABY1980223; @DEREYCK1996347; @HERROELEN1998279].
Over the years, the list of parameters that should measure instance complexity has grown a lot and each index / parameter may have its advantages and disadvantages.

For each instance on the [website](http://solutionsupdate.ugent.be/rcpsp), several parameters describe the network topology, complexity, and resources. Table \@ref(tab:parameter) shows a list of all parameters that are considered in this report. All parameters are briefly described and it can be noticed that some seem vert similar.

```{r parameter, echo = FALSE, message = FALSE, warning = FALSE}
parameters <- read_excel(
  path = find_root_file(
    "data", "RCPLIB (Parameters and BKS).xlsx",
    criterion = has_file("RCPSP_survival.Rproj")
  ),
  sheet = "Parameter Overview",
  skip = 2
) %>%
  rename(Category = `Paramater category`) %>%
  dplyr::select(1:3) %>%
  mutate(Category = na.locf(Category),
         Parameter = str_replace(Parameter, "#", "nb"),
         Parameter = str_replace_all(Parameter, " ", "-"),
         Parameter = str_replace_all(Parameter, fixed("("), "-"),
         Parameter = str_replace_all(Parameter, fixed(")"), "")
         )

n_nc <- sum(parameters$Category == "Network Topology")
n_ci <- sum(parameters$Category == "Complexity indictors")
n_rp <- sum(parameters$Category == "Resource parameters")
n_hc <- sum(parameters$Category == "Hardness classification")

parameters %>%
  dplyr::filter(Category %in% c("Network Topology",
                                "Complexity indictors",
                                "Resource parameters",
                                "Hardness classification")) %>%
  dplyr::select(-Category) %>%
  kable(booktabs = TRUE,
        caption = "Instance topology, complexity, resource parameters, and hardness classification.",
        col.names = c("", "")) %>%
  kableExtra::group_rows(group_label = "Network Topology",
                         start_row = 1,
                         end_row = n_nc) %>%
  kableExtra::group_rows(group_label = "Complexity indictors",
                         start_row = n_nc + 1,
                         end_row = n_nc + n_ci) %>%
  kableExtra::group_rows(group_label = "Resource parameters",
                         start_row = 1 + n_nc + n_ci,
                         end_row = n_nc + n_ci + n_rp) %>%
  kableExtra::group_rows(group_label = "Hardness classification",
                         start_row = 1 + n_nc + n_ci + n_rp,
                         end_row = n_nc + n_ci + n_rp + n_hc) %>%
  kableExtra::kable_styling(font_size = 9) %>%
  kableExtra::column_spec(1, width = "0.5in") %>%
  kableExtra::column_spec(2, width = "5.5in")
```

# Methodology

The main goal of this research is to explore which RCPSP instance parameters can best predict whether or not the instance can be solved and, if it can be solved, how long it will take to find the optimal solution. Table \@ref(tab:parameter) clearly shows that there is a myriad of possible complexity indicators and it is not known which ones can best predict instance complexity.
In contrast, new parameters and indices are still being developed without properly proving their merit (ability to predict the time to find an optimal solution) in addition to the already existing indices.

Most researchers will set a maximum calculation time to find the optimal solution for each problem instance.
If the optimal solution is not found within this time limit, the instance is right-censored.
We further hypothesize that some problem instances will be too hard to solve, no matter how much time is allowed to find an optimal solution.
Due to the complexity of some problems, for instance, solving it might require more memory than what is available on the machine that implements the algorithm.
In this case, the computer will crash and will never find the optimal solution.

Therefor, we will use cure models to model the time to find the optimal solution. The independent variables will be the complexity parameters of Table \@ref(tab:parameter).
In cure models, a fraction of the population will never experience the event of interest.
Translated to our problem setting, this means that some problem instances will never be solved to optimality.
In essence, this means that the true time to solve until optimality for these instances is $\infty$.
In this case, *cure models* should be used to properly estimate the effect of the different complexity parameters on the time to solve until optimality.

There are two main families of cure regression models: (1) mixture cure models and (2) promotion cure models.
Both types of cure models model a *cure fraction* $1 - p$; the probability that an instance cannot be solved, and a *survival function* $S(t)$ for those instances that can be solved to optimality.
Mixture cure models allow more flexibility as the cure fraction and survival function may depend on different covariates. The main downside is that it is harder to fit these type of models.
Promotion cure models are easier to interpret as they maintain a proportional hazard structure. The downside is that both the cure fraction and survival function will depend on the same covariates.



```{r load-cv-data, echo = FALSE, message = FALSE, warning = FALSE}
data_cv <- read_excel(
  path = find_root_file(
    "data", "RCPLIB (Parameters and BKS).xlsx",
    criterion = has_file("RCPSP_survival.Rproj")
  ),
  sheet = "CV",
  skip = 0
) %>%
  rename(nbR = `#R`) %>%
  rename(nbAct = `#Act`) %>%
  rename(nblR = `#lR`) %>%
  rename(nbhR = `#hR`)
colnames(data_cv)[2] <- "IDset"
colnames(data_cv) <- str_replace_all(colnames(data_cv), " ", "-")
colnames(data_cv) <- str_replace_all(colnames(data_cv), fixed("("), "-")
colnames(data_cv) <- str_replace_all(colnames(data_cv), fixed(")"), "")

data_cv_cv <- read_csv2(
  file = find_root_file(
    "data", "CV_CV.csv",
    criterion = has_file("RCPSP_survival.Rproj")
  ),
  skip = 6
) %>%
  as.data.frame() %>%
  dplyr::select(1:4) %>%
  mutate(author = "CV")

data_cv_wz <- read_csv2(
  file = find_root_file(
    "data", "CV_WZ.csv",
    criterion = has_file("RCPSP_survival.Rproj")
  ),
  skip = 6
) %>%
  dplyr::select(1:4) %>%
  mutate(author = "WZ")

data_cv_c <- read_csv2(
  file = find_root_file(
    "data", "CV_C.csv",
    criterion = has_file("RCPSP_survival.Rproj")
  ),
  skip = 6
) %>%
  dplyr::select(1:4) %>%
  mutate(author = "C")
data_cv_all <- data_cv_cv %>%
  rbind(data_cv_wz) %>%
  rbind(data_cv_c) %>%
  mutate(Type = as.factor(Type),
         author = factor(as.factor(author),
                         levels = c("CV", "WZ", "C")))
M <- data_cv %>%
  dplyr::select(
    parameters %>%
      dplyr::filter(Category %in%
                      c("Network Topology",
                        "Complexity indictors",
                        "Resource parameters",
                        "Hardness classification")) %>%
      pull(Parameter) &
                      where(is.numeric)) %>%
  cor()
```

Exploring the correlation between the long list of complexity indices, it is clear that many indices are highly correlated. The correlation matrices for the CV instances (Figure \@ref(fig:cv-cormat) and \@ref(fig:cv-cormat-reorder)) show that some parameters measure almost the same thing.
The correlation between RC and hRC, for example is `r round(M["RC", "hRC"],2)` while the correlation between RC and FS22 is `r round(M["RC", "FS22"],2)`!
To avoid multicollinearity problems, it is clear that some parameters should therefor not be added together in a statistical model.
We will apply regularization techniques to be able to work with the multicollinearity.


##---------------EXPLANATION OF REGULARIZATION TECHNIQUES HERE----------------##

```{r cv-cormat, echo = FALSE, message = FALSE, warning = FALSE, fig.cap = "Correlation between the different numeric parameters of interest.", fig.width = 9, fig.height = 6}

#corrplot(M)
order.AOE <- corrMatOrder(M, order = 'AOE')
order.FPC <- corrMatOrder(M, order = 'FPC')
order.hc <- corrMatOrder(M, order = 'hclust')
order.hc2 <- corrMatOrder(M, order = 'hclust', hclust.method = 'ward.D')

M.AOE <- M[order.AOE, order.AOE]
M.FPC <- M[order.FPC, order.FPC]
M.hc  <- M[order.hc, order.hc]
M.hc2 <- M[order.hc2, order.hc2]
corrplot(M)
#corrplot(M.AOE)
#corrplot(M.FPC)
#corrplot(M.hc)
```

```{r cv-cormat-reorder, echo = FALSE, message = FALSE, warning = FALSE, fig.cap = "Correlation between the different numeric parameters of interest (hierarchical clustering reordering).", fig.width = 9, fig.height = 6}
corrplot(M.hc)
corrRect.hclust(M.hc2, k = 6)
```


# Results

In this section, we describe our results. In section \@ref(subsec-exploration) we explore the data and select a subset of the data for further exploration.

## Data exploration {#subsec-exploration}

## Cure model

# Conclusion and future research

## CV dataset
The Coelho-Vanhoucke (CV) dataset consists of 623 RCPSP instances, first described in @cv2020 that can be downloaded from [here](https://www.projectmanagement.ugent.be/research/data).
Figure \@ref(fig:cv-cormat) shows the correlation between different parameters (Table \@ref(tab:parameter)) in all 623 instances.
Figure \@ref(fig: cv-cormat-reorder) shows the same correlation matrix with the rows and column reordered to show highly correlated hierarchical clusters.

As of September 2023, three different authors have submitted their run-time results and best (or optimal) solution to each of the instances;
- @cv2020 (CV) designed this dataset with difficult to solve instances and provided their heuristic solutions to some of them.
- @watermeyer2022partition (WZ) was the first one to add further solutions to improve upon the already achieved results.
- @creemers2021 (C) recently added his results and is able to solve almost all instances.


In this chapter, we compare the run times reported by each of the researchers for each of the instances. If a researcher is unable to find the optimal solution (within a certain time limit), they might still report the best solution that was found.


### Run times: Kaplan Meier

In this chapter, we look at the different run times to find an optimal solution. If an optimal solution is not found, a lower bound and/or heuristic solution was reported instead. If a non-optimal solution is reported, we consider the run time to be right-censored.

Figure \@ref(fig:cv-compare-authors) shows the run times for different authors. It can be seen than @cv2020 solves none of the instances to optimality. They designed this dataset to be difficult such that it can serve as a benchmarking dataset for new RCPSP algorithms. @watermeyer2022partition can solve almost 30% of all instances to optimality. Since they stop their algorithm after 3600 seconds, all other instances are right censored at that time. Lastly, @creemers2021 allows for a maximum run time of 48 hours. If no optimal solution is found after that, the instance is right-censored. 

Table \@ref(tab:cv-compare-authors-quantiles) shows different quantiles for each author with log-log 95% confidence intervals.

```{r cv-compare-authors, fig.cap="Comparing the run time for the different authors.", echo = FALSE, message = FALSE, warning = FALSE}
data_cv_all_1 <- data_cv_all %>%
  group_by(ID, author) %>%
  summarize(is_optimal = any(Type == "optimal"),
            Time = mean(Time)) %>%
  ungroup() %>%
  mutate(Time = ifelse(is_optimal,
                       Time,
                       ifelse(author == "C",
                              48*60*60*1000,
                              ifelse(author == "WZ",
                                     3600000,
                                     20*60*60*1000))
                       ),
         status = 1*is_optimal)
s1 <- survfit(Surv(Time, status) ~ author, data = data_cv_all_1)
survfit2(Surv(Time, status) ~ author, data = data_cv_all_1) %>%
  ggsurvfit() +
  labs(
    x = "milliseconds",
    y = "Proportion of instances not solved to optimality"
    )
```

```{r cv-compare-authors-quantiles, fig.cap="Comparing the run time for the different authors.", echo = FALSE, message = FALSE, warning = FALSE}
library(biostatUZH)
qKM10 <- quantileKM(data_cv_all_1$Time, data_cv_all_1$status,
                    group = data_cv_all_1$author, quant = 0.1,
                    conf.level = 0.95, conf.type = "log-log")
qKM25 <- quantileKM(data_cv_all_1$Time, data_cv_all_1$status,
                    group = data_cv_all_1$author, quant = 0.25,
                    conf.level = 0.95, conf.type = "log-log")
qKM50 <- quantileKM(data_cv_all_1$Time, data_cv_all_1$status,
                    group = data_cv_all_1$author, quant = 0.5,
                    conf.level = 0.95, conf.type = "log-log")
qKM75 <- quantileKM(data_cv_all_1$Time, data_cv_all_1$status, 
                  group = data_cv_all_1$author, quant = 0.75,
                  conf.level = 0.95, conf.type = "log-log")
qKM90 <- quantileKM(data_cv_all_1$Time, data_cv_all_1$status,
                    group = data_cv_all_1$author, quant = 0.9,
                    conf.level = 0.95, conf.type = "log-log")

qKM <- data_frame(author = c("CV", "WZ", "C"),
                  q90 = qKM90$quantities %>%
                    as.data.frame() %>%
                    mutate(q = sprintf("%.0f, [%.0f, %.0f]", quantile,
                                       lower.ci, upper.ci)) %>% dplyr::pull(q),
                  
                  q75 = qKM75$quantities %>%
                    as.data.frame() %>%
                    mutate(q = sprintf("%.0f, [%.0f, %.0f]", quantile,
                                       lower.ci, upper.ci)) %>% dplyr::pull(q),

                  q50 = qKM50$quantities %>%
                    as.data.frame() %>%
                    mutate(q = sprintf("%.0f, [%.0f, %.0f]", quantile,
                                       lower.ci, upper.ci)) %>% dplyr::pull(q),

                  q25 = qKM25$quantities %>%
                    as.data.frame() %>%
                    mutate(q = sprintf("%.0f, [%.0f, %.0f]", quantile,
                                       lower.ci, upper.ci)) %>% dplyr::pull(q),

                  q10 = qKM10$quantities %>%
                    as.data.frame() %>%
                    mutate(q = sprintf("%.0f, [%.0f, %.0f]", quantile,
                                       lower.ci, upper.ci)) %>% dplyr::pull(q))
qKM %>%
  kable(caption = "Quantiles and confidence intervals for the time to solve to optimality.",
        booktabs = TRUE) %>%
  kableExtra::kable_styling() %>%
  kableExtra::column_spec(1, width = "0.4in") %>%
  kableExtra::column_spec(2:6, width = "1in")
```

### Runtime with different instance parameters

In this chapter, we explore the different parameters and how they influence the survival time. Since all parameters are continuous variables, we split the instance set into three or four equally-sized groups where the parameter varies from low to high. The Kaplan Meier curves will allow us to look for patterns. Parameters that allow us to distinguish easy from hard instances will be of interest for subsequent statistical models.


```{r display-parameter-analysis, results = "asis", echo = FALSE, eval = TRUE}
#c("CNC", "AD", "TF", "Wprec", "RF", "RU", "RS", "RC")
to_do <- data_cv %>%
  dplyr::select(c(6:38, 58:61)) %>%
  dplyr::select(where(is.numeric)) %>%
  colnames()
rmd <- sapply(
  to_do,
  function(id) {
    knit_expand("_cv_analysis_parameter.Rmd", id = id)
  }
) %>%
  paste(collapse = "\n\n")
cat(knit(text = rmd, quiet = TRUE))
```

### Survival tree

```{r message=FALSE, warning=FALSE, include=FALSE}
library(LongCART)
data_cv_tree <- data_cv_all_1 %>%
  left_join(data_cv %>%
              dplyr::select(c(2, 6:38, 58:61)) %>%
              dplyr::select(where(is.numeric)),
            by = join_by(ID == IDset)) %>%
  add_rownames() %>%
  dplyr::filter(author != "CV") %>%
  mutate(Time = ifelse(Time == 0, 0.000001, Time))
out.tree <- SurvCART(data = data_cv_tree, patid = "rowname", 
              censorvar = "status", timevar = "Time", 
              gvars = dput(colnames(data_cv_tree)[-c(1:6)]),  
              tgvars = c(rep(1, 34)), 
              time.dist = "exponential", 
              event.ind = 1, alpha = 0.05, minsplit = 80, minbucket = 40, 
              print = TRUE)
data_cv_tree_c <- data_cv_tree %>% dplyr::filter(author == "C")
data_cv_tree_wz <- data_cv_tree %>% dplyr::filter(author == "WZ")
out.tree.c <- SurvCART(data = data_cv_tree_c, patid = "rowname", 
              censorvar = "status", timevar = "Time", 
              gvars = dput(colnames(data_cv_tree)[-c(1:6)]),  
              tgvars = c(rep(1, 34)), 
              time.dist = "exponential", 
              event.ind = 1, alpha = 0.05, minsplit = 80, minbucket = 40, 
              print = TRUE)
#these two do not work
# out.tree.wz <- SurvCART(data = data_cv_tree_wz, patid = "rowname", 
#               censorvar = "status", timevar = "Time", 
#               gvars = dput(colnames(data_cv_tree)[-c(1:6)]),  
#               tgvars = c(rep(1, 34)), 
#               time.dist = "exponential", 
#               event.ind = 1, alpha = 0.05, minsplit = 80, minbucket = 40, 
#               print = TRUE)
# out.tree.with.author <- SurvCART(data = data_cv_tree, patid = "rowname", 
#               censorvar = "status", timevar = "Time", 
#               gvars = dput(colnames(data_cv_tree)[-c(1:6, 41)]),  
#               tgvars = c(rep(1, 34)), 
#               time.dist = "exponential", 
#               event.ind = 1, alpha = 0.05, minsplit = 80, minbucket = 40, 
#               print = TRUE)
```
```{r cv-tree-all, fig.cap="A survival tree for the whole dataset.", echo = FALSE, message = FALSE, warning = FALSE}
par(xpd = TRUE)
plot(out.tree, compress = TRUE)
text(out.tree, use.n = TRUE)
```
```{r cv-tree-all-km, fig.cap="Kaplan-Meier curves for the different groups for the survival tree for the whole dataset.", echo = FALSE, message = FALSE, warning = FALSE, eval = FALSE}
KMPlot(out.tree, scale.time = 1000, type = 1)
```

```{r cv-tree-C, fig.cap="A survival tree for the Creemers algorithm.", echo = FALSE, message = FALSE, warning = FALSE, eval = FALSE}
par(xpd = TRUE)
plot(out.tree.c, compress = TRUE)
text(out.tree.c, use.n = TRUE)
```
```{r cv-tree-C-km, fig.cap="Kaplan-Meier curves for the different groups for the survival tree for the Creemers algorithm.", echo = FALSE, message = FALSE, warning = FALSE, eval = FALSE}
KMPlot(out.tree.c, scale.time = 1000, type = 1)
```

### AFT with XGBoost
https://mlr3book.mlr-org.com/chapters/chapter13/beyond_regression_and_classification.html#sec-survival
https://arxiv.org/pdf/2008.08080v2.pdf
https://www.rpubs.com/avinashbarnwal123/aft
```{r echo = FALSE, message = FALSE, warning = FALSE, include = FALSE}
library(xgboost)

```


# Bibliography{-}